{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and augmenting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations import HorizontalFlip, CenterCrop, Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a directory\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, split = 0.1):\n",
    "    # Loading images and masks\n",
    "    X = sorted(glob(os.path.join(path, \"images\", \"*.jpg\")))\n",
    "    Y = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n",
    "\n",
    "    # Spliting data into training and testing\n",
    "    split_size = int(len(X) * split)\n",
    "    X_train, X_test = train_test_split(X, test_size = split_size, random_state = 42)\n",
    "    y_train, y_test = train_test_split(Y, test_size = split_size, random_state = 42)\n",
    "\n",
    "    return (X_train, X_test), (y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of data\n",
    "data_path = \"people_segmentation\"\n",
    "(X_train, X_test), (y_train, y_test) = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5111, 5111, 567, 567)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories to save augmented data\n",
    "create_dir(\"new_data/train/image\")\n",
    "create_dir(\"new_data/train/mask\")\n",
    "create_dir(\"new_data/test/image\")\n",
    "create_dir(\"new_data/test/mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(images, masks, save_path, augment = True):\n",
    "    Height = 256\n",
    "    Width = 256\n",
    "\n",
    "    for x, y in zip(images, masks):\n",
    "        # Extract the name of file\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        # Reading the image and mask\n",
    "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        y = cv2.imread(y, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Augmenting the data\n",
    "        if augment:\n",
    "\n",
    "            # Flipping images horizantaly\n",
    "            aug = HorizontalFlip(p = 0.2)\n",
    "            augmented = aug(image = x, mask = y)\n",
    "            x1 = augmented['image']\n",
    "            y1 = augmented['mask']\n",
    "\n",
    "            # Rotating images\n",
    "            aug = Rotate(p = 1, limit = 45)\n",
    "            augmented = aug(image = x, mask = y)\n",
    "            x2 = augmented['image']\n",
    "            y2 = augmented['mask']\n",
    "\n",
    "            X = [x, x1, x2]\n",
    "            Y = [y, y1, y2]\n",
    "\n",
    "        else:\n",
    "            X = [x]\n",
    "            Y = [y]\n",
    "\n",
    "        index = 0\n",
    "        for i, m in zip(X, Y):\n",
    "            try:\n",
    "                # Try center cropping\n",
    "                aug = CenterCrop(Height, Width, p = 1)\n",
    "                augmented = aug(image = i, mask = m)\n",
    "                i = augmented['image']\n",
    "                m = augmented['mask']\n",
    "\n",
    "            except Exception as e:\n",
    "                # If can't center crop then we resize it\n",
    "                i = cv2.resize(i, (Width, Height))\n",
    "                m = cv2.resize(m, (Width, Height))\n",
    "\n",
    "            tmp_image_name = f\"{name}_{index}.jpg\"\n",
    "            tmp_mask_name = f\"{name}_{index}.jpg\"\n",
    "\n",
    "            image_path = os.path.join(save_path, 'image', tmp_image_name)\n",
    "            mask_path = os.path.join(save_path, 'mask', tmp_mask_name)\n",
    "\n",
    "            cv2.imwrite(image_path, i)\n",
    "            cv2.imwrite(mask_path, m)\n",
    "\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation\n",
    "augment_data(X_train, y_train, \"new_data/train/\", augment=False)\n",
    "augment_data(X_test, y_test, \"new_data/test/\", augment=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D, UpSampling2D, Reshape, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import tensorflow as tf\n",
    "\n",
    "def SqueezeAndExcite(inputs, ratio = 8):\n",
    "    init = inputs\n",
    "    filters = init.shape[-1]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    \n",
    "    x = init * se\n",
    "\n",
    "    return x\n",
    "\n",
    "def ASPP(inputs):\n",
    "    shape = inputs.shape\n",
    "\n",
    "    # Image pooling\n",
    "    y1 = AveragePooling2D(pool_size = (shape[1], shape[2]))(inputs)\n",
    "    y1 = Conv2D(256, 1, padding = 'same', use_bias = False)(y1)\n",
    "    y1 = BatchNormalization()(y1)\n",
    "    y1 = Activation('relu')(y1)\n",
    "    y1 = UpSampling2D((shape[1], shape[2]), interpolation = 'bilinear')(y1)\n",
    "    \n",
    "    # 1x1 conv\n",
    "    y2 = Conv2D(256, 1, padding = 'same', use_bias = False)(inputs)\n",
    "    y2 = BatchNormalization()(y2)\n",
    "    y2 = Activation('relu')(y2)\n",
    "\n",
    "    # 3x3 conv with rate 6\n",
    "    y3 = Conv2D(256, 3, padding = 'same', use_bias = False, dilation_rate = 6)(inputs)\n",
    "    y3 = BatchNormalization()(y3)\n",
    "    y3 = Activation('relu')(y3)\n",
    "\n",
    "    # 3x3 conv with rate 12\n",
    "    y4 = Conv2D(256, 3, padding = 'same', use_bias = False, dilation_rate = 12)(inputs)\n",
    "    y4 = BatchNormalization()(y4)\n",
    "    y4 = Activation('relu')(y4)\n",
    "\n",
    "    # 3x3 conv with rate 18\n",
    "    y5 = Conv2D(256, 3, padding = 'same', use_bias = False, dilation_rate = 18)(inputs)\n",
    "    y5 = BatchNormalization()(y5)\n",
    "    y5 = Activation('relu')(y5)\n",
    "\n",
    "    # Concatenating features\n",
    "    y = Concatenate()([y1, y2, y3, y4, y5])\n",
    "    y = Conv2D(256, 1, padding = 'same', use_bias = False)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "def deeplabv3_plus(shape):\n",
    "    inputs = Input(shape)\n",
    "\n",
    "    # Encoder\n",
    "    encoder = ResNet50(weights = 'imagenet', include_top = False, input_tensor = inputs)\n",
    "\n",
    "    image_features = encoder.get_layer('conv4_block6_out').output\n",
    "    x_a = ASPP(image_features)\n",
    "    x_a = UpSampling2D((4, 4), interpolation = 'bilinear')(x_a)\n",
    "    \n",
    "    x_b = encoder.get_layer(\"conv2_block2_out\").output\n",
    "    x_b = Conv2D(48, 1, padding = 'same', use_bias = False)(x_b)\n",
    "    x_b = BatchNormalization()(x_b)\n",
    "    x_b = Activation('relu')(x_b)\n",
    "\n",
    "    x = Concatenate()([x_a, x_b])\n",
    "    x = SqueezeAndExcite(x)\n",
    "\n",
    "    x = Conv2D(256, 3, padding = 'same', use_bias = False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(256, 3, padding = 'same', use_bias = False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SqueezeAndExcite(x)\n",
    "\n",
    "    x = UpSampling2D((4, 4), interpolation = 'bilinear')(x)\n",
    "    x = Conv2D(1, 1)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5111 5111\n",
      "567 567\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from metrics import dice_loss, dice_coef, iou\n",
    "\n",
    "Height = 256\n",
    "Width = 256\n",
    "\n",
    "def Shuffling(x, y):\n",
    "    x, y = shuffle(x, y, random_state = 42)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def load_data(path):\n",
    "    x = sorted(glob(os.path.join(path, 'image', '*.jpg')))\n",
    "    y = sorted(glob(os.path.join(path, 'mask', '*.jpg')))\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def read_image(path):\n",
    "    path= path.decode()\n",
    "\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = x / 255.0\n",
    "    x = x.astype(np.float32)\n",
    "\n",
    "    return x\n",
    "\n",
    "def read_mask(path):\n",
    "    path= path.decode()\n",
    "\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = x.astype(np.float32)\n",
    "    x = np.expand_dims(x, axis = -1)\n",
    "\n",
    "    return x\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse_(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    x, y = tf.numpy_function(_parse_, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([Height, Width, 3])\n",
    "    y.set_shape([Height, Width, 1])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(X, Y, batch = 2):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(15)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "create_dir(\"files\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "lr = 1e-4\n",
    "n_epochs = 20\n",
    "model_path = os.path.join(\"files\", \"model.h5\")\n",
    "csv_path = os.path.join(\"files\", \"data.csv\")\n",
    "\n",
    "dataset_path = 'new_data'\n",
    "train_path = os.path.join(dataset_path, 'train')\n",
    "test_path = os.path.join(dataset_path, 'test')\n",
    "\n",
    "x_train, y_train = load_data(train_path)\n",
    "x_train, y_train = Shuffling(x_train, y_train)\n",
    "\n",
    "x_test, y_test = load_data(test_path)\n",
    "x_test, y_test = Shuffling(x_test, y_test)\n",
    "\n",
    "print(len(x_train), len(y_train))\n",
    "print(len(x_test), len(y_test))\n",
    "\n",
    "train_dataset = tf_dataset(x_train, y_train, batch = batch_size)\n",
    "valid_dataset = tf_dataset(x_test, y_test, batch  =batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 128, 128, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 64, 64, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 1024)  0           ['conv4_block6_out[0][0]']       \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 1, 1, 256)    262144      ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1, 1, 256)   1024        ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 16, 16, 256)  262144      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 16, 256)  2359296     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 16, 256)  2359296     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 16, 16, 256)  2359296     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1, 1, 256)    0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 16, 16, 256)  0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 16, 1280  0           ['up_sampling2d[0][0]',          \n",
      "                                )                                 'activation_1[0][0]',           \n",
      "                                                                  'activation_2[0][0]',           \n",
      "                                                                  'activation_3[0][0]',           \n",
      "                                                                  'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 16, 16, 256)  327680      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 64, 48)   12288       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 16, 256)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 64, 64, 48)  192         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0          ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 64, 64, 48)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 304)  0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 304)         0           ['concatenate_1[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 1, 304)    0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1, 1, 38)     11552       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1, 1, 304)    11552       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 64, 64, 304)  0           ['concatenate_1[0][0]',          \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 64, 256)  700416      ['tf.math.multiply[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 64, 256)  589824      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 256)         0           ['activation_8[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 1, 1, 256)    0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1, 1, 32)     8192        ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1, 1, 256)    8192        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 64, 64, 256)  0          ['activation_8[0][0]',           \n",
      " )                                                                'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 25  0          ['tf.math.multiply_1[0][0]']     \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 256, 256, 1)  257         ['up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 256, 256, 1)  0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17,869,697\n",
      "Trainable params: 17,834,913\n",
      "Non-trainable params: 34,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = deeplabv3_plus((Height, Width, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = dice_loss, optimizer = Adam(lr), metrics = [dice_coef, iou, Recall(), Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose = 0, save_best_only = True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor = 0.1, patience = 5, min_lr = 1e-7, verbose = 1),\n",
    "        CSVLogger(csv_path),\n",
    "        TensorBoard(),\n",
    "        EarlyStopping(monitor='val_loss', patience = 10, restore_best_weights = False),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "320/320 [==============================] - 117s 328ms/step - loss: 0.1027 - dice_coef: 0.8974 - iou: 0.8171 - recall: 0.9349 - precision: 0.8837 - val_loss: 0.8354 - val_dice_coef: 0.1622 - val_iou: 0.0907 - val_recall: 0.0866 - val_precision: 0.7790 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "320/320 [==============================] - 101s 315ms/step - loss: 0.0629 - dice_coef: 0.9371 - iou: 0.8829 - recall: 0.9529 - precision: 0.9277 - val_loss: 0.3147 - val_dice_coef: 0.6818 - val_iou: 0.5240 - val_recall: 0.5558 - val_precision: 0.9021 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "320/320 [==============================] - 100s 313ms/step - loss: 0.0472 - dice_coef: 0.9529 - iou: 0.9110 - recall: 0.9667 - precision: 0.9441 - val_loss: 0.0705 - val_dice_coef: 0.9297 - val_iou: 0.8694 - val_recall: 0.9353 - val_precision: 0.9292 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "320/320 [==============================] - 101s 316ms/step - loss: 0.0366 - dice_coef: 0.9634 - iou: 0.9301 - recall: 0.9750 - precision: 0.9558 - val_loss: 0.0591 - val_dice_coef: 0.9410 - val_iou: 0.8896 - val_recall: 0.9410 - val_precision: 0.9452 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "320/320 [==============================] - 99s 311ms/step - loss: 0.0287 - dice_coef: 0.9714 - iou: 0.9448 - recall: 0.9803 - precision: 0.9652 - val_loss: 0.0611 - val_dice_coef: 0.9386 - val_iou: 0.8851 - val_recall: 0.9337 - val_precision: 0.9475 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "320/320 [==============================] - 100s 312ms/step - loss: 0.0253 - dice_coef: 0.9747 - iou: 0.9511 - recall: 0.9820 - precision: 0.9698 - val_loss: 0.0617 - val_dice_coef: 0.9388 - val_iou: 0.8861 - val_recall: 0.9615 - val_precision: 0.9209 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "320/320 [==============================] - 101s 314ms/step - loss: 0.0352 - dice_coef: 0.9648 - iou: 0.9327 - recall: 0.9715 - precision: 0.9604 - val_loss: 0.1289 - val_dice_coef: 0.8717 - val_iou: 0.7763 - val_recall: 0.8010 - val_precision: 0.9647 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "320/320 [==============================] - 126s 394ms/step - loss: 0.0243 - dice_coef: 0.9757 - iou: 0.9530 - recall: 0.9825 - precision: 0.9708 - val_loss: 0.0799 - val_dice_coef: 0.9203 - val_iou: 0.8541 - val_recall: 0.8922 - val_precision: 0.9550 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "320/320 [==============================] - ETA: 0s - loss: 0.0274 - dice_coef: 0.9726 - iou: 0.9471 - recall: 0.9791 - precision: 0.9678\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "320/320 [==============================] - 189s 591ms/step - loss: 0.0274 - dice_coef: 0.9726 - iou: 0.9471 - recall: 0.9791 - precision: 0.9678 - val_loss: 0.0608 - val_dice_coef: 0.9400 - val_iou: 0.8880 - val_recall: 0.9449 - val_precision: 0.9375 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "320/320 [==============================] - 174s 543ms/step - loss: 0.0211 - dice_coef: 0.9789 - iou: 0.9589 - recall: 0.9856 - precision: 0.9737 - val_loss: 0.0525 - val_dice_coef: 0.9479 - val_iou: 0.9021 - val_recall: 0.9543 - val_precision: 0.9448 - lr: 1.0000e-05\n",
      "Epoch 11/20\n",
      "320/320 [==============================] - 164s 512ms/step - loss: 0.0176 - dice_coef: 0.9824 - iou: 0.9657 - recall: 0.9875 - precision: 0.9788 - val_loss: 0.0520 - val_dice_coef: 0.9485 - val_iou: 0.9030 - val_recall: 0.9527 - val_precision: 0.9472 - lr: 1.0000e-05\n",
      "Epoch 12/20\n",
      "320/320 [==============================] - 173s 542ms/step - loss: 0.0164 - dice_coef: 0.9836 - iou: 0.9680 - recall: 0.9884 - precision: 0.9802 - val_loss: 0.0517 - val_dice_coef: 0.9488 - val_iou: 0.9037 - val_recall: 0.9514 - val_precision: 0.9489 - lr: 1.0000e-05\n",
      "Epoch 13/20\n",
      "320/320 [==============================] - 186s 583ms/step - loss: 0.0156 - dice_coef: 0.9844 - iou: 0.9695 - recall: 0.9890 - precision: 0.9812 - val_loss: 0.0508 - val_dice_coef: 0.9498 - val_iou: 0.9054 - val_recall: 0.9526 - val_precision: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 14/20\n",
      "320/320 [==============================] - 181s 565ms/step - loss: 0.0150 - dice_coef: 0.9850 - iou: 0.9707 - recall: 0.9895 - precision: 0.9819 - val_loss: 0.0503 - val_dice_coef: 0.9503 - val_iou: 0.9064 - val_recall: 0.9533 - val_precision: 0.9500 - lr: 1.0000e-05\n",
      "Epoch 15/20\n",
      "320/320 [==============================] - 163s 510ms/step - loss: 0.0144 - dice_coef: 0.9856 - iou: 0.9717 - recall: 0.9900 - precision: 0.9825 - val_loss: 0.0499 - val_dice_coef: 0.9507 - val_iou: 0.9070 - val_recall: 0.9544 - val_precision: 0.9494 - lr: 1.0000e-05\n",
      "Epoch 16/20\n",
      "320/320 [==============================] - 164s 513ms/step - loss: 0.0140 - dice_coef: 0.9860 - iou: 0.9726 - recall: 0.9903 - precision: 0.9830 - val_loss: 0.0499 - val_dice_coef: 0.9508 - val_iou: 0.9072 - val_recall: 0.9539 - val_precision: 0.9500 - lr: 1.0000e-05\n",
      "Epoch 17/20\n",
      "320/320 [==============================] - 184s 576ms/step - loss: 0.0136 - dice_coef: 0.9865 - iou: 0.9734 - recall: 0.9907 - precision: 0.9835 - val_loss: 0.0495 - val_dice_coef: 0.9511 - val_iou: 0.9078 - val_recall: 0.9550 - val_precision: 0.9495 - lr: 1.0000e-05\n",
      "Epoch 18/20\n",
      "320/320 [==============================] - 178s 555ms/step - loss: 0.0131 - dice_coef: 0.9869 - iou: 0.9743 - recall: 0.9910 - precision: 0.9841 - val_loss: 0.0492 - val_dice_coef: 0.9514 - val_iou: 0.9084 - val_recall: 0.9546 - val_precision: 0.9504 - lr: 1.0000e-05\n",
      "Epoch 19/20\n",
      "320/320 [==============================] - 165s 514ms/step - loss: 0.0126 - dice_coef: 0.9874 - iou: 0.9752 - recall: 0.9914 - precision: 0.9846 - val_loss: 0.0491 - val_dice_coef: 0.9516 - val_iou: 0.9087 - val_recall: 0.9557 - val_precision: 0.9498 - lr: 1.0000e-05\n",
      "Epoch 20/20\n",
      "320/320 [==============================] - 165s 515ms/step - loss: 0.0123 - dice_coef: 0.9877 - iou: 0.9759 - recall: 0.9916 - precision: 0.9850 - val_loss: 0.0487 - val_dice_coef: 0.9519 - val_iou: 0.9091 - val_recall: 0.9553 - val_precision: 0.9509 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "model_hist = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = n_epochs,\n",
    "    validation_data = valid_dataset,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = model_hist.history['loss']\n",
    "val_loss = model_hist.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = model_hist.history['iou']\n",
    "val_acc = model_hist.history['val_iou']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training IOU')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation IOU')\n",
    "plt.title('Training and validation IOU')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IOU')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "\n",
    "with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef, 'dice_loss': dice_loss}):\n",
    "    model = tf.keras.models.load_model(\"files/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 567 - 567\n"
     ]
    }
   ],
   "source": [
    "create_dir(\"results\")\n",
    "\n",
    "dataset_path = \"new_data\"\n",
    "valid_path = os.path.join(dataset_path, \"test\")\n",
    "x_test, y_test = load_data(valid_path)\n",
    "print(f\"Test: {len(x_test)} - {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 245ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_results(image, mask, y_pred, save_image_path):\n",
    "    ## i - m - yp - yp*i\n",
    "    line = np.ones((Height, 10, 3)) * 128\n",
    "\n",
    "    mask = np.expand_dims(mask, axis=-1)    # (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  ## (512, 512, 3)\n",
    "    mask = mask * 255\n",
    "\n",
    "    y_pred = np.expand_dims(y_pred, axis=-1)    # (512, 512, 1)\n",
    "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)  # (512, 512, 3)\n",
    "\n",
    "    masked_image = image * y_pred\n",
    "    y_pred = y_pred * 255\n",
    "\n",
    "    cat_images = np.concatenate([image, line, mask, line, y_pred, line, masked_image], axis=1)\n",
    "    cv2.imwrite(save_image_path, cat_images)\n",
    "\n",
    "SCORE = []\n",
    "for x, y in zip(x_test, y_test):\n",
    "        \" Extract the name \"\n",
    "        name = x.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        \" Reading the image \"\n",
    "        image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        x = image/255.0\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        \" Reading the mask \"\n",
    "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        \" Prediction \"\n",
    "        y_pred = model.predict(x)[0]\n",
    "        y_pred = np.squeeze(y_pred, axis=-1)\n",
    "        y_pred = y_pred > 0.5\n",
    "        y_pred = y_pred.astype(np.int32)\n",
    "\n",
    "        \" Saving the prediction \"\n",
    "        save_image_path = f\"results\\{name}.jpg\"\n",
    "        save_results(image, mask, y_pred, save_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
